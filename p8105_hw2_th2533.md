p8105\_hw2\_th2533
================
Tianheng Hu
9/23/2020

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

# Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df =
    read_xlsx(
      "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "Mr. Trash Wheel",
      range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
      sports_balls = round(sports_balls),
      sports_balls = as.integer(sports_balls)
    )
```

Read in precipitation data.

``` r
precip_2018 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018,precip_2017)

left_join(precip_df, month_df, by="month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trash Wheel collector in
Baltimore, Maryland. As trash enters the inner harbor, the trashwheel
collects that trash, and stores it in a dumpster. The dataset contains
information on year, month, and trash collected, include some specific
kinds of trash. There are a total of 344 rows in our final dataset.
Additional data sheets include month precipitation data.

  - The median number of sports balls found in a dumpster in 2017 was 8
  - The total precipitation in 2018 was 70.33 inches.

# Problem 2

Read NYC Transit data.

``` r
transit_df = 
  read_csv(
  "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry,
         vending, entrance_type, ada) %>% 
  mutate(
    entry = ifelse(entry =="YES", 1, 0),
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
  ) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_name", 
    values_to = "route_num") %>% 
  drop_na(route_num) %>% 
  select(-route_name)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

This dataset contains information related to each entry and exit for
each subway station in NYC. It has information on subway line, station
name, station latitude/longitude, routes served, entry, vending,
entrance type, and ADA compliance.There are total 4270 rows and 9 in our
final dataset. The entry variable has been converted from a character to
a logical variable. This data is not tidy at first because we have many
columns for route information. Now it is tidy.

  - There are 465 distinct stations in NYC.

  - Among those, there are 84.

  - There are 0.39 of station entrances / exits without vending allow
    entrance

  - There are 60 stations serve the A train. Among those, 17 are ADA
    compliant.

# Problem 3

Read the dataset that contains the number of national politicians who
are democratic or republican at any given time.

``` r
pols_df = 
  read_csv(
  "./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>%
  separate(mon, c("year", "month", "day")) %>% 
  mutate(
    month = as.integer(month),
    year = as.integer(year),
    month = month.name[month]) %>% 
  mutate (president = ifelse(prez_dem == 1, "dem", "gop")) %>%
  select(-prez_gop, -prez_dem, -day)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Read the dataset that contains Standard & Poor’s stock market index

``` r
snp_df = 
  read_csv(
  "./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>%
  separate(date, c("month", "day", "year")) %>% 
  mutate(
    month = as.integer(month),
    year = as.integer(year),
    month = month.name[month]) %>% 
  select(year, month, close)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Read the unemployment dataset.

``` r
unemp_df = 
  read_csv(
  "./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month", 
    values_to = "unemp_rate") 
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
month_abb_df = 
  tibble(
    month_abb = month.abb,
    month_name = month.name
  )

unemp_df = 
  unemp_df %>% 
  left_join(month_abb_df, by = c("month" = "month_abb")) %>% 
  select(year = Year, month = month_name, unemp_rate) 
```

Merge the three datasets.

``` r
final_df = full_join(pols_df, snp_df, by = c("year","month"))
final_df = full_join(final_df, unemp_df, by = c("year","month"))
```

The pols\_df dataset contains the number of national politicians who are
democratic or republican at any given time. It has the information on
whether the president is a democratic or republican and the number of
governors, senator and representatives are democreatic or republican.

The snp\_df dataset contains Standard & Poor’s stock market index at a
given time.

The unemp\_df dataset contains the unemployment rate at a given time.

The resulting dataset which combines the three has 828 rows and 11
columns.

  - It contains information from 1947 and 2015.
  - It also contains information on whether the president is a
    democratic or republican.
  - It tells us the S\&P index at a time. The mean for the index is
    472.8470595.
  - It also gives us the unemployment rate at a time. The mean is
    5.8583969.
