---
title: "p8105_hw2_th2533"
author: "Tianheng Hu"
date: "9/23/2020"
output: github_document
---


```{r setup}
library(tidyverse)
library(readxl)


```

# Problem 1

Read the Mr. Trashwheel dataset.

```{r}
trashwheel_df =
    read_xlsx(
      "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "Mr. Trash Wheel",
      range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
      sports_balls = round(sports_balls),
      sports_balls = as.integer(sports_balls)
    )
                 
```

Read in precipitation data.
```{r}
precip_2018 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)

```

Now combine annual precipitation

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018,precip_2017)

left_join(precip_df, month_df, by="month")
```

This dataset contains information from the Mr. Trash Wheel collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data.

* The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.


# Problem 2


Read NYC Transit data.
```{r}
transit_df = 
  read_csv(
  "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry,
         vending, entrance_type, ada) %>% 
  mutate(
    entry = ifelse(entry =="YES", "Entry", "No_entry")
  )


```

This dataset contains information related to each entry and exit for each subway station in NYC. It has information on subway line, station name, station latitude/longitude, routes served, entry, vending, entrance type, and ADA compliance.There are total `r nrow(transit_df)` rows and `r ncol(transit_df)` in our final dataset. The entry variable has been converted from a character to a logical variable. This data is not tidy because we have many columns for route information.

* There are `r transit_df %>% distinct(station_name, line) %>% count()` distinct stations in NYC.
* Among those, there are `r transit_df %>% filter(ada == "TRUE") %>% distinct(station_name, line) %>% count()`.
* There are `r transit_df %>% filter(vending == "YES") %>% distinct(station_name, line,entry) %>% count(entry)


```{r}

transit_new = 
  transit_df %>% 
  mutate(
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
  ) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_name", 
    values_to = "route_num") %>% 
  drop_na(route_num)
```

There are `r transit_new %>% filter(route_num == "A") %>% distinct(station_name, line) %>% count()` stations serve the A train. Among those, `r transit_new %>% filter(route_num == "A") %>% distinct(station_name, line, ada) %>% filter(ada == "TRUE") %>% count()` are ADA compliant.



# Problem 3

Read the dataset that contains the number of national politicians who are democratic or republican at any given time.
```{r}
pols_df = 
  read_csv(
  "./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>%
  separate(mon, c("year", "month", "day")) %>% 
  mutate(
    month = as.integer(month),
    year = as.integer(year),
    month = month.name[month]) %>% 
  mutate (president = ifelse(prez_dem == 1, "dem", "gop")) %>%
  select(-prez_gop, -prez_dem, -day)

```

Read the dataset that contains Standard & Poor’s stock market index

```{r}
snp_df = 
  read_csv(
  "./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>%
  separate(date, c("month", "day", "year")) %>% 
  mutate(
    month = as.integer(month),
    year = as.integer(year),
    month = month.name[month]) %>% 
  select(year, month, close)
  
```

Read the unemployment dataset.

```{r}
unemp_df = 
  read_csv(
  "./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month", 
    values_to = "unemp_rate") 

month_abb_df = 
  tibble(
    month_abb = month.abb,
    month_name = month.name
  )

unemp_df = 
  unemp_df %>% 
  left_join(month_abb_df, by = c("month" = "month_abb")) %>% 
  select(year = Year, month = month_name, unemp_rate) 

```


Merge the three datasets.

```{r}

final_df = full_join(pols_df, snp_df, by = c("year","month"))
final_df = full_join(final_df, unemp_df, by = c("year","month"))

```

The pols_df dataset contains the number of national politicians who are democratic or republican at any given time. It has the information on whether the president is a democratic or republican and the number of governors, senator and representatives are democreatic or republican.

The snp_df dataset contains Standard & Poor’s stock market index at a given time.

The unemp_df dataset contains the unemployment rate at a given time.

The resulting dataset which combines the three has `r nrow(final_df)` rows and `r ncol(final_df)` columns. 

* It contains information from `r min(final_df %>% pull(year))` and `r max(final_df %>% pull(year))`. 
* It also contains information on whether the president is a democratic or republican. 
* It tells us the S&P index at a time. The mean for the index is `r mean(final_df %>% drop_na() %>% pull(close))`. 
* It also gives us the unemployment rate at a time. The mean is `r mean(final_df %>% drop_na() %>% pull(unemp_rate))`. 
